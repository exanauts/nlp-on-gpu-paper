% Jinja Template for Latex file
% Copyright François Pacaud, 2023

\documentclass{article}

\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage{xcolor,bm,url}
\usepackage{booktabs}
\usepackage{array}
\usepackage{tikz}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{proposition}[theorem]{Proposition}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\theoremstyle{remark}
\newtheorem{remark}{Remark}

\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\argmin}{arg\,min}
\DeclareMathOperator{\nullspace}{null}
\DeclareMathOperator{\rangespace}{range}
\newcommand{\cond}{\kappa_2}
\newcommand{\epstol}{\mathbf{u}}
\newcommand{\cactive}{\mathcal{B}}
\newcommand{\cinactive}{\mathcal{N}}

% \title{Nonlinear programming on GPU: current state-of-the-art}
\title{Approaches to nonlinear programming on SIMD architectures}
\author{François Pacaud \and
Sungho Shin \and
Alexis Montoison \and
Michel Schanen \and
Mihai Anitescu
}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
  Solving nonlinear programs requires the
  successive solutions of large-scale indefinite symmetric matrices using
  sparse factorization routines that rely
  on notoriously hard-to-parallelize pivoting operations.
  A workaround is to reformulate the successive Karush-Kuhn-Tucker (KKT) systems
  in a form more amenable for the GPU,
  by reducing it down to a symmetric positive-definite condensed
  system whose factorization using Cholesky does not require pivoting.
  In this paper, we analyze the performance of two different condensed-space methods
  when used inside an interior-point solver.
  We prove that the condensed matrices exhibit structured ill-conditioning,
  limiting the loss of accuracy when computing a descent direction.
  We implement the two methods on current state-of-the-art SIMD architecture, using the newly
  released cuDSS solver on NVIDIA GPUs. We illustrate their strengths and weaknesses
  on large-scale instances taken from the PGLIB and the COPS benchmarks.
  Our findings indicate that current GPUs excel in rapidly computing results,
  achieving a moderate convergence tolerance---at a rate 10 times faster
  than that of state-of-the-art CPU routines---though they exhibit
  limited robustness. Such results are promising for the future of large-scale nonlinear programming on upcoming SIMD architectures.
\end{abstract}


% \tableofcontents


\input{sections/introduction.tex}
\input{sections/ipm.tex}
\input{sections/kkt_systems.tex}
\input{sections/conditioning.tex}
\input{sections/numerics.tex}

\section{Conclusion}
This article moves one step further in the solution of generic nonlinear
programs on GPU architectures. We have compared two approaches
to solve the KKT systems arising at each interior-point iteration, both
based on a condensation procedure. Despite the forming of a ill-conditioned
matrix, our theoretical analysis show that the loss of accuracy is benign
in floating point arithmetic, thanks to the specific properties of IPM.
Our numerical results show that both methods are competitive to solve large-scale
nonlinear programs. Compared to the state-of-the-art linear solvers in HSL, we obtain 10x speed-up on large-scale OPF instances
and quasi-dense instances ({\tt elec}). The results are more mitigated
on the various instances of the COPS benchmark, but the performance remains
always competitive with HSL.

In the future, we are planning to robustify the performance of
the two condensed KKT methods, in particular, to stabilize the convergence
for small tolerance (below $10^{-8}$). Notably, the sparse Cholesky solver
can be adapted further to the specific needs of the IPM~\cite{wright1999modified}.
Improving the two methods on the GPU would allow to solve large-scale
problems intractable on the classical CPU architecture --- such as the multiperiod
and security-constrained OPF problems --- especially when used in conjunction
with a Schur-complement approach.


\bibliographystyle{siam}
\bibliography{biblio.bib}

\end{document}
