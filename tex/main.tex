% Jinja Template for Latex file
% Copyright François Pacaud, 2023

\documentclass[smallextended]{svjour3}

\usepackage{amsmath,amsfonts,amssymb}
\usepackage{xcolor,bm,url}
\usepackage{booktabs}
\usepackage{array}
\usepackage{tikz}
% \usepackage{cleveref} % cleveref is not working with Springer journal classes
\usepackage{xspace}

% \newtheorem{theorem}{Theorem}[section]
% \newtheorem{lemma}[theorem]{Lemma}
% \newtheorem{corollary}[theorem]{Corollary}
\newtheorem{assumption}[theorem]{Assumption}
% \newtheorem{proposition}[theorem]{Proposition}
% \theoremstyle{definition}
% \newtheorem{definition}[theorem]{Definition}
% \newtheorem{example}[theorem]{Example}
% \theoremstyle{remark}
% \newtheorem{remark}{Remark}

\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\argmin}{arg\,min}
\DeclareMathOperator{\nullspace}{Ker}
\DeclareMathOperator{\rangespace}{range}
\DeclareMathOperator{\inertia}{inertia}
\newcommand{\ldlt}{$\mathrm{LDL^T}$\xspace}
\newcommand{\lblt}{$\mathrm{LBL^T}$\xspace}
\newcommand{\llt}{$\mathrm{LL^T}$\xspace}
\newcommand{\lu}{$\mathrm{LU}$\xspace}
\newcommand{\CG}{\textsc{Cg}\xspace}
\newcommand{\CR}{\textsc{Cr}\xspace}
\newcommand{\CAR}{\textsc{cAr}\xspace}
\newcommand{\cond}{\kappa_2}
\newcommand{\epstol}{\mathbf{u}}
\newcommand{\cactive}{\mathcal{B}}
\newcommand{\cinactive}{\mathcal{N}}

% \title{Nonlinear programming on GPU: current state-of-the-art}
\title{Approaches to nonlinear programming on GPU architectures}
% \title{Approaches to nonlinear optimization on GPU architectures} ?
\author{François Pacaud \and
Sungho Shin \and
Alexis Montoison \and
Michel Schanen \and
Mihai Anitescu
}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
  This paper explores an interior-point method for solving large-scale constrained nonlinear programs with the aid of graphics processing units (GPUs).
  The interior-point method involves resolving a sequence of symmetric indefinite linear systems, or Karush-Kuhn-Tucker (KKT) systems,
  which become increasingly ill-conditioned as we approach to the solution.
  Solving the KKT systems with traditional sparse factorization methods involve numerical pivoting that makes parallelization difficult.
  This paper introduces two condensed space interior-point methods, HybridKKT and LiftedKKT.
  Both reformulate the challenging KKT systems into symmetric positive-definite systems, more amenable for GPU parallelization using Cholesky factorization.
  Although condensed KKT systems are more prone to ill-conditioning than indefinite KKT systems, they exhibit structured ill-conditioning that mitigates the loss of accuracy.
  We implement the two methods on GPUs with MadNLP.jl, a solver interfaced with the NVIDIA library cuDSS for solving sparse positive definite systems and ExaModels.jl for evaluating models on GPUs.
  We assess the performance on large-scale problems from the PGLIB and COPS benchmarks, revealing that GPUs can achieve up to a tenfold speed increase compared to CPUs.
\end{abstract}


% \tableofcontents


\input{sections/introduction.tex}
\input{sections/ipm.tex}
\input{sections/kkt_systems.tex}
\input{sections/conditioning.tex}
\input{sections/numerics.tex}

\section{Conclusion}
This article moves one step further in the solution of generic nonlinear
programs on GPU architectures. We have compared two approaches
to solve the KKT systems arising at each interior-point iteration, both
based on a condensation procedure.
Despite the formation of an ill-conditioned matrix, our theoretical analysis shows that the loss of accuracy is benign in floating-point arithmetic, thanks to the specific properties of the interior-point method.
Our numerical results show that both methods are competitive to solve large-scale
nonlinear programs.
Compared to the state-of-the-art HSL linear solvers, we achieve a 10x speed-up on large-scale OPF instances and quasi-dense instances (\texttt{elec}). While the results are more varied across the instances of the COPS benchmark, our performance consistently remains competitive with HSL.

Looking ahead, our future plans involve enhancing the robustness of the two condensed KKT methods, particularly focusing on stabilizing convergence for small tolerances (below $10^{-8}$).
It is worth noting that the sparse Cholesky solver can be further customized to meet the specific requirements of the interior-point method~\cite{wright1999modified}.
% Add a sentence about NCL on GPU?
Enhancing the two methods on the GPU would enable the resolution of large-scale problems that are currently intractable on classical CPU architectures.
Examples include multiperiod and security-constrained OPF problems, particularly when combined with a Schur-complement approach.

\small
\bibliographystyle{spmpsci}
\bibliography{biblio.bib}
\normalsize

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
