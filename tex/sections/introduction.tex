\section{Introduction}
Graphical processing units (GPUs) have become the most popular parallel computing architecture
for scientific computing, driven by their success in machine learning.
GPUs offer massive parallel computing capability for applications
that can exploit coarse-grain parallelism and high-memory bandwidth.
As such, the library CUDA has revolutionized high-performance computing (HPC) by democratizing parallel capabilities previously exclusive to expensive supercomputers.
In the post-Moore's law era, GPUs are becoming more power-efficient than CPUs for running parallel workloads, as they require fewer transistors to process multiple tasks in parallel.
This efficiency is further enhanced by technologies like ``single instruction, multiple data'' (SIMD), which allow GPUs to perform the same operation on multiple data simultaneously, maximizing throughput and efficiency.

While GPUs have made significant strides in enhancing machine learning applications, their adoption in the mathematical programming community has been relatively limited.
This limitation stems primarily from the fact that most optimization solvers were developed in the 1990s and are heavily optimized for CPU architectures.
Additionally, the utilization of GPUs has been impeded by the challenges associated with sparse matrix factorization routines, which are inherently difficult to parallelize on SIMD architectures. Nevertheless, recent years have witnessed notable advancements that are reshaping this landscape.

\begin{enumerate}
  \item \textbf{Improved sparse matrix operations}: The performance of sparse matrix operations has seen substantial improvements in the CUDA library, largely attributed to the integration of novel tensor cores in recent GPUs~\cite{markidis2018nvidia}.
  \item \textbf{Interest in batch optimization}: There is a growing interest in solving optimization problems in batch mode, for problems sharing the same structure but with different parameters~\cite{amos2017optnet,pineda2022theseus}.
  \item \textbf{Advancements in automatic differentiation}: GPUs offer unparalleled performance for automatic differentiation, benefiting both machine learning ~\cite{jax2018github} and scientific computing applications \cite{enzyme2021}. Engineering problems often exhibit recurring patterns throughout the model. Once these patterns are identified, they can be evaluated in parallel within a SIMD framework, enabling near speed-of-light performance~\cite{shin2023accelerating}.
  \item \textbf{Role in exascale computing}: With the emergence of new exascale architectures, GPUs have become indispensable in achieving high-performance computing, particularly in supercomputing environments.
\end{enumerate}

For all the reasons listed before, there is an increasing interest
to solve optimization problems on the GPU.

\subsection{Current state-of-the-art on GPU}

\paragraph{GPU for mathematical programming.}
The machine learning community has been a strong advocate for porting
mathematical optimization on the GPU. One of the most promising
applications is embedding mathematical programs inside neural networks,
a task that requires batching the solution of the optimization model
for the training algorithm to be
efficient~\cite{amos2017optnet,pineda2022theseus}.  This has led to
the development of prototype code solving thousands of (small)
optimization problems in parallel on the GPU.  However, it is not
trivial to adapt such code to solve large-scale optimization problems,
as the previous prototypes are reliant on dense linear solvers to
compute the descent direction.

For this reason, practitioners often resort to using first-order
methods on GPUs, leveraging level-1 and level-2 BLAS operations that
are more amenable to parallel computation.
First-order algorithms depend mostly on (sparse) matrix-vector operations, that run
very efficiently on modern GPUs. Hence, we can counterbalance
the relative inaccuracy of the first-order method by running more
iterations of the algorithm.
A recent breakthrough~\cite{lu2023cupdlp,lu2023cupdlp2} demonstrates
that a first-order algorithm can surpass the performance of Gurobi, a
commercial solver, in tackling large-scale linear programs. This
performance gain is made possible by executing the first-order
iterations solely on the GPU through an optimized codebase, thereby
solving the LP problems to $10^{-8}$ accuracy.


\paragraph{GPU for nonlinear programming.}
The success of first-order algorithms in classical mathematical programming
relies on the convexity of the problem. Thus, their approaches are nontrivial to replicate
in nonlinear programming. Most engineering problems embed complex
physical equations that are likely to break any convex structure in the problem.
Previous experiments on the OPF problem have shown that even a simple
algorithm as ADMM has trouble converging as soon as the convergence
tolerance is set below $10^{-3}$~\cite{kim2021leveraging}.

Thus, second-order methods continue to be a competitive option, particularly
for scenarios that require higher levels of accuracy and robust convergence.
Second-order algorithms require solving a Newton step at each
iteration, an operation relying on non-trivial sparse linear algebra operations.
The previous generation of GPU-accelerated sparse linear
solvers were lagging behind their CPU equivalents, as illustrated in
subsequent surveys~\cite{tasseff2019exploring,swirydowicz2021linear}.
Fortunately, sparse solvers on GPUs are getting increasingly better with the newest
generations of GPUs.
In particular, NVIDIA has released in November 2023
a new sparse direct solver that implements different sparse factorization routines: {\tt cuDSS}. Our
preliminary benchmark has shown {\tt cuDSS} is significantly
faster than the previous sparse solvers using NVIDIA GPUs.
The new NVIDIA Grace CPU architecture could also be a game changer in the future of sparse linear solvers, thanks to fast communication between the CPU and GPU.
Furthermore, variants of interior point methods have been proposed
that does not require the use of numerical pivoting.
As these algorithms do not require expensive numerical pivoting
operations, parallelized sparse solvers can be effectively exploited
within the solution algorithms.
Coupled with a GPU-accelerated automatic differentiation library and a
sparse Cholesky solver, these nonlinear programming solvers can solve
Optimal Power Flow (OPF) problems 10x faster than state-of-the-art
methods~\cite{shin2023accelerating}.

An alternative thread of research is investigating the solution of the Newton steps
on the GPU using iterative methods such as Krylov methods.
Iterative methods often require non-trivial reformulation of the Newton step to avoid
ill-conditioned matrices, which has limited their use inside interior-point
algorithms. New results are giving promising outlooks for convex problems~\cite{ghannad2022linear},
but nonconvex problems often require an Augmented Lagrangian reformulation
to be tractable~\cite{cao2016augmented,regev2023hykkt}. In particular,
\cite{regev2023hykkt} presents an interesting use of the Golub and Greif
hybrid method~\cite{golub2003solving} to solve the KKT systems arising in
the interior-point methods, with promising results on the GPU.
The null-space method, also known as the reduced Hessian strategy,
is also a good candidate for solving KKT systems on the GPU.
The null-space method reduces the KKT system down to
a medium-sized dense matrix, which then can be factorized efficiently on the GPU.
Our previous research has shown that the method plays nicely with the interior-point
methods if the number of degrees of freedom in the problem is relatively small~\cite{pacaud2022condensed}.

\subsection{Contributions}
In this article, we assess the current capabilities of modern GPUs
to solve large-scale nonconvex nonlinear programs to optimality.
We focus on the two condensed-space methods
introduced respectively in~\cite{regev2023hykkt,shin2023accelerating}.
We re-use classical results from~\cite{wright1998ill} to show
that for both methods, the condensed matrix exhibits
structured ill-conditioning that limits the loss of accuracy in
the descent direction (provided the interior-point algorithm satisfies
some standard assumptions).
We implement both algorithms inside the GPU-accelerated solver MadNLP,
and leverage the GPU-accelerated automatic differentiation
backend ExaModels~\cite{shin2023accelerating}.
The interior-point algorithm runs entirely on the GPU, from
the evaluation of the model (using ExaModels) to the solution of
the KKT system (using a condensed-space method running on the GPU).
We use CUDSS.jl \cite{Montoison_CUDSS}, a Julia interface to the NVIDIA library {\tt cuDSS} to solve
the condensed KKT systems.
We evaluate the strengths
and weaknesses of both methods, in terms of accuracy and runtime.
Extending beyond the classical OPF instances previously examined in our work, we incorporate large-scale problems sourced from the COPS nonlinear benchmark~\cite{dolan2004benchmarking}.
Our assessment involves comparing the performance achieved on the GPU with that of a state-of-the-art method executed on the CPU.
The findings reveal that the condensed-space methods demonstrate a remarkable 10x acceleration in solving large-scale OPF instances when utilizing the GPU.
However, performance outcomes on the COPS benchmark exhibit more variability.

\subsection{Notations}
By default, the norm $\|\cdot\|$ refers to the 2-norm.
We define the conditioning of a matrix $A$ as
$\cond(A) = \| A \| \|A^{-1} \|$.
For any real number $x$, we denote $\widehat{x}$ as its floating
point representation.
We denote $\epstol$ as the smallest positive number such that
$\widehat{x} \leq (1 + \tau) x$ for $|\tau| < \epstol$.
In double precision, $\epstol = 1.1 \times 10^{-16}$.
We use the following notations to proceed with our error analysis.
For $p \in \mathbb{N}$ and a positive variable $h$:
\begin{itemize}
  \item We write $x = O(h^p)$ if there exists a constant $b > 0$
    such that $\| x \| \leq b h^p$;
  \item We write $x = \Omega(h^p)$ if there exists a constant $a > 0$
    such that $\| x \| \geq a h^p$;
  \item We write $x = \Theta(h^p)$ if there exists two constants $0 < a < b$
    such that $a h^p \leq \| x \| \leq b h^p$.
\end{itemize}
